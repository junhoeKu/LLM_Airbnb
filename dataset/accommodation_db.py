# -*- coding: utf-8 -*-
"""ìˆ™ì†ŒDB.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VAkhexlIr9flP1oJzvxLek0FUu4MAShU
"""

import pandas as pd
import pickle
import numpy as np

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
final_df = pd.read_csv("/content/drive/MyDrive/dataset/final(0519).csv")
# final_df_price = pd.read_csv("/content/drive/MyDrive/dataset/final_price(0502).csv")

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
final_df["Title"].fillna("ì œëª© ë¯¸ì…ë ¥", inplace=True)
final_df["LocationDescription"].fillna("ìœ„ì¹˜ ì •ë³´ ì—†ìŒ", inplace=True)
final_df["MainDescription"].fillna("ìƒì„¸ ì„¤ëª… ì—†ìŒ", inplace=True)
final_df["SpaceDescription"].fillna("ê³µê°„ ì„¤ëª… ì—†ìŒ", inplace=True)
final_df["GuestAccessDescription"].fillna("ì´ìš© ê°€ëŠ¥ ê³µê°„ ì •ë³´ ì—†ìŒ", inplace=True)
final_df["Host_ResponseRate"].fillna("ì‘ë‹µë¥  ì •ë³´ ì—†ìŒ", inplace=True)
final_df["Host_ResponseTime"].fillna("ì‘ë‹µ ì‹œê°„ ì •ë³´ ì—†ìŒ", inplace=True)
final_df["amenities_SelfCheckIn"].fillna("ì…€í”„ ì²´í¬ì¸ ì—¬ë¶€ ëª¨ë¦„", inplace=True)
final_df["CheckIn_Start"].fillna("ì²´í¬ì¸ ì‹œê°„ ëª¨ë¦„", inplace=True)
final_df["CheckOut_End"].fillna("ì²´í¬ì•„ì›ƒ ì‹œê°„ ëª¨ë¦„", inplace=True)

# ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ì •ì˜
neighborhood_mapping = {
    "Ma-po-gu": "ë§ˆí¬êµ¬",
    "Yong-san-gu": "ìš©ì‚°êµ¬",
    "Yongsan-gu": "ìš©ì‚°êµ¬",
    "Gang-nam-gu": "ê°•ë‚¨êµ¬",
    "Jong-no-gu": "ì¢…ë¡œêµ¬",
    "Jung-gu": "ì¤‘êµ¬",
    "Myeong-dong": "ëª…ë™",
    "Gwa-nak-gu": "ê´€ì•…êµ¬",
    "Yeong-deung-po-gu": "ì˜ë“±í¬êµ¬",
    "Gwang-jin-gu": "ê´‘ì§„êµ¬",
    "Seo-cho-gu": "ì„œì´ˆêµ¬",
    "Seocho-gu": "ì„œì´ˆêµ¬",
    "Dong-dae-mun-gu": "ë™ëŒ€ë¬¸êµ¬",
    "Song-pa-gu": "ì†¡íŒŒêµ¬",
    "Seo-dae-mun-gu": "ì„œëŒ€ë¬¸êµ¬",
    "Seong-buk-gu": "ì„±ë¶êµ¬",
    "Eun-pyeong-gu": "ì€í‰êµ¬",
    "Seong-dong-gu": "ì„±ë™êµ¬",
    "Dong-jak-gu": "ë™ì‘êµ¬",
    "Gang-buk-gu": "ê°•ë¶êµ¬",
    "Sin-chon-dong": "ì‹ ì´Œë™",
    "Jung-nang-gu": "ì¤‘ë‘êµ¬",
    "Seong-su 2 ga 1 dong": "ì„±ìˆ˜2ê°€1ë™",
    "Gu-ro-gu": "êµ¬ë¡œêµ¬",
    "Geum-cheon-gu": "ê¸ˆì²œêµ¬",
    "No-won-gu": "ë…¸ì›êµ¬",
    "Do-bong-gu": "ë„ë´‰êµ¬",
    "Goyang-si": "ê³ ì–‘ì‹œ"
}

def map_neighborhood_to_korean(name: str) -> str:
    return neighborhood_mapping.get(name, name)  # ì—†ëŠ” ê°’ì€ ê·¸ëŒ€ë¡œ ë°˜í™˜

# ìƒˆ ì»¬ëŸ¼ ìƒì„±
final_df["LocalizedNeighbourhood_ML"] = final_df["LocalizedNeighbourhood_ML"].apply(map_neighborhood_to_korean)

final_df1 = final_df.iloc[150:300,:]
final_df2 = final_df.iloc[5000:,:]

final_df.columns

import pandas as pd
from tqdm import tqdm
from openai import OpenAI
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from functools import lru_cache

# OpenAI API í‚¤ ì„¤ì •
client = OpenAI(api_key="")

# ì¤‘ë³µ ìš”ì²­ ë°©ì§€ ìºì‹œ
@lru_cache(maxsize=50000)
def call_openai_cached(text):
    prompt = f"""ì…ë ¥ ë¬¸ì¥ì´ í•œêµ­ì–´ë¼ë©´ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ê³ , ì˜ì–´ë¼ë©´ í•œêµ­ì–´ë¡œ ë²ˆì—­í•˜ì„¸ìš”.:
"{text}" """
    for attempt in range(10):  # ìµœëŒ€ 3íšŒ ì¬ì‹œë„
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì •í™•í•˜ê³  ê¹”ë”í•œ ë²ˆì—­ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                timeout=10  # ì´ˆë‹¹ íƒ€ì„ì•„ì›ƒ ì„¤ì •
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            if attempt == 2:
                print(f"ğŸ”´ Failed after 3 tries: {text[:50]}... | Error: {e}")
                return text
            time.sleep(1 + attempt)  # ì ì§„ì  ë°±ì˜¤í”„

# ë²ˆì—­ ëŒ€ìƒ: Title ì—´
texts = final_df1['Amenities'].tolist()

# ë³‘ë ¬ ë²ˆì—­ í•¨ìˆ˜
def parallel_translate(texts, max_workers=10):
    results = [None] * len(texts)
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(call_openai_cached, text): i for i, text in enumerate(texts)}

        for future in tqdm(as_completed(futures), total=len(texts)):
            i = futures[future]
            try:
                results[i] = future.result()
            except Exception as e:
                print(f"ğŸ”´ Unexpected error: {e}")
                results[i] = texts[i]
    return results

# ì‹¤í–‰
translated_titles = parallel_translate(texts)
final_df1["Amenities_korean"] = translated_titles

final_df = pd.concat([final_df1, final_df2])

final_df.to_csv('/content/drive/MyDrive/dataset/final(0519).csv', index=False)
# final_df["amenities_korean"] = final_df["Amenities"].progress_apply(translate_to_korean)

# âœ… 1. CSV -> Pickle ë³€í™˜ + FAISS ì¤€ë¹„ìš© ë²¡í„° ì €ì¥ ìŠ¤í¬ë¦½íŠ¸
import pandas as pd
import pickle
from sentence_transformers import SentenceTransformer
import numpy as np

embedding_model = SentenceTransformer("jhgan/ko-sroberta-multitask")

# ì„ë² ë”© í…ìŠ¤íŠ¸ êµ¬ì„± í•¨ìˆ˜
def build_embedding_text(row):
    if row['PersonCapacity'] >= 6:
        capacity_tag = "ë‹¨ì²´ ì—¬í–‰ê°ì—ê²Œ ì í•©í•œ ë„‰ë„‰í•œ ê³µê°„ì…ë‹ˆë‹¤.\n"
    elif row['PersonCapacity'] >= 3:
        capacity_tag = "ì‘ì€ ê·¸ë£¹ì´ë‚˜ ê°€ì¡± ì—¬í–‰ì— ì ë‹¹í•œ ìˆ™ì†Œì…ë‹ˆë‹¤.\n"
    else:
        capacity_tag = "1~2ì¸ ì—¬í–‰ìì—ê²Œ ì•Œë§ì€ ê³µê°„ì…ë‹ˆë‹¤.\n"

    return (
        f"ë¦¬ìŠ¤íŒ…ID: {row['Airbnb_ListingID']}\n"
        f"ìˆ™ì†Œ ì´ë¦„: {row['title_korean']}\n"
        f"ìœ„ì¹˜: {row['LocalizedNeighbourhood_ML']}\n"
        f"ìœ„ì¹˜ ì„¤ëª…: {row['LocationDescription']}\n"
        f"ìˆ™ì†Œ ì†Œê°œ: {row['MainDescription']}\n"
        f"ê³µê°„ ì„¤ëª…: {row['SpaceDescription']}\n"
        f"ìµœëŒ€ ìˆ˜ìš© ì¸ì›: {row['PersonCapacity']}ëª…\n"
        f"{capacity_tag}"
        f"ìš•ì‹¤ ìˆ˜: {row['Bathrooms']} / ì¹¨ì‹¤ ìˆ˜: {row['Bedrooms']} / ì¹¨ëŒ€ ìˆ˜: {row['Beds']}\n"
        f"ìŠˆí¼í˜¸ìŠ¤íŠ¸ ì—¬ë¶€: {'ì˜ˆ' if row['isSuperhost'] else 'ì•„ë‹ˆì˜¤'}\n"
        f"í˜¸ìŠ¤íŠ¸ ì‚¬ìš© ì–¸ì–´: {row['HostLanguages_Verbose']}\n"
        f"ë³„ì : {row['Rating']}ì  ({row['ReviewCounts']}ê°œ ë¦¬ë·°)\n"
        f"ì–´ë©”ë‹ˆí‹°: {row['Amenities']}\n"
        f"ë¦¬ë·° ìš”ì•½: {row['ReviewSummary']}\n"
    )


# ì„ë² ë”© í…ìŠ¤íŠ¸ì™€ ë²¡í„° ìƒì„±
final_df['embedding_text'] = final_df.apply(build_embedding_text, axis=1)
embeddings = embedding_model.encode(final_df['embedding_text'].tolist(), show_progress_bar=True, batch_size=64)

# numpy arrayë¡œ ë³€í™˜
dense_vectors = np.array(embeddings)

# ì €ì¥ (Listing ID í¬í•¨ DF ìœ ì§€)
with open("/content/drive/MyDrive/dataset/airbnb_data_ì¤€íšŒ.pkl", "wb") as f:
    pickle.dump({
        "df": final_df[['Airbnb_ListingID', 'embedding_text'] +
                      [c for c in final_df.columns if c not in ['Airbnb_ListingID', 'embedding_text']]],
        "vectors": dense_vectors
    }, f)

print("âœ… Pickle ì €ì¥ ì™„ë£Œ: /content/drive/MyDrive/dataset/airbnb_data_ì¤€íšŒ.pkl")

print(final_df_price.isnull().sum().to_string())

final_df_price.head()

final_df_price['price_diff']= final_df_price['Price_Per_Night'] - final_df_price['Price_Per_Night_mean']
price_comment = (
    "í‰ê· ë³´ë‹¤ ì €ë ´í•œ í¸ì…ë‹ˆë‹¤." if price_diff < 0 else
    "í‰ê· ë³´ë‹¤ ë‹¤ì†Œ ë†’ì€ í¸ì…ë‹ˆë‹¤." if price_diff > 0 else
    "í‰ê· ê³¼ ë™ì¼í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤."
)
f"ìš”ê¸ˆ ë¹„êµ: {price_comment}\n"

# âœ… 1. CSV -> Pickle ë³€í™˜ + FAISS ì¤€ë¹„ìš© ë²¡í„° ì €ì¥ ìŠ¤í¬ë¦½íŠ¸
import pandas as pd
import pickle
from sentence_transformers import SentenceTransformer
import numpy as np

embedding_model = SentenceTransformer("jhgan/ko-sroberta-multitask")

# ì„ë² ë”© í…ìŠ¤íŠ¸ êµ¬ì„± í•¨ìˆ˜
def build_embedding_text(row):
    # ê°€ê²© ì°¨ì´ ë° ë³€í™”ìœ¨ ê³„ì‚°
    price_diff = row['total_price'] - row['total_price_mean']
    price_change_ratio = (price_diff / row['total_price_mean']) * 100 if row['total_price_mean'] else 0

    # ìš”ê¸ˆ ë¹„êµ ë¬¸êµ¬ ('í‰ì†Œ' ê¸°ì¤€ Â±5% í—ˆìš©)
    if abs(price_change_ratio) <= 5:
        price_comment = "í‰ì†Œ ìˆ˜ì¤€ì˜ ìš”ê¸ˆì…ë‹ˆë‹¤."
    elif price_change_ratio < -5:
        price_comment = "í‰ì†Œë³´ë‹¤ ì €ë ´í•œ í¸ì…ë‹ˆë‹¤."
    else:
        price_comment = "í‰ì†Œë³´ë‹¤ ë‹¤ì†Œ ë†’ì€ í¸ì…ë‹ˆë‹¤."

    # íŠ¹ê°€ ì—¬ë¶€ íƒœê·¸
    special_offer_note = " íŠ¹ê°€ ìˆ™ì†Œë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.\n" if price_change_ratio < -20 else ""

    return (
        f"ë¦¬ìŠ¤íŒ…ID: {row['Airbnb_ListingID']}\n"
        f"ì˜ˆì•½ ë‚ ì§œ: {row['Calendar_Date']}\n"
        f"ì˜ˆì•½ ê°€ëŠ¥ ì—¬ë¶€: {'ê°€ëŠ¥' if row['isAvailable'] else 'ë¶ˆê°€ëŠ¥'}\n"
        f"ì˜ˆì•½ ê°€ëŠ¥ ë‚ ì§œ: {row['Available_Ranges']}\n"
        f"ìµœì†Œ ìˆ™ë°•ì¼: {row['Min_Nights']}ë°• / ìµœëŒ€ ìˆ™ë°•ì¼: {row['Max_Nights']}ë°•\n"
        f"ì²´í¬ì¸ ê°€ëŠ¥ ì—¬ë¶€: {'ê°€ëŠ¥' if row['Available_For_Checkin'] else 'ë¶ˆê°€ëŠ¥'} / "
        f"ì²´í¬ì•„ì›ƒ ê°€ëŠ¥ ì—¬ë¶€: {'ê°€ëŠ¥' if row['Available_For_Checkout'] else 'ë¶ˆê°€ëŠ¥'}\n"
        f"ì˜ˆì•½ ì¸ì›: {row['Guests']}ëª…\n"
        f"1ë°• ìš”ê¸ˆ: {row['Price_Per_Night']}ì›\n"
        f"ì²­ì†Œë¹„: {row['Cleaning_Fee']}ì› / ì—ì–´ë¹„ì•¤ë¹„ ìˆ˜ìˆ˜ë£Œ: {row['Airbnb_Service_Fee']}ì›\n"
        f"1ë°• ì´ìš”ê¸ˆ: {row['total_price']}ì›\n"
        f"ìš”ê¸ˆ ë¹„êµ: {price_comment} (í‰ì†Œ ëŒ€ë¹„ {price_change_ratio:.1f}% {'ìƒìŠ¹' if price_change_ratio > 0 else 'í•˜ë½' if price_change_ratio < 0 else 'ë³€ë™ ì—†ìŒ'})\n"
        f"{special_offer_note}"
        f"í‰ê·  1ë°• ìš”ê¸ˆ: {row['Price_Per_Night_mean']}ì›\n"
        f"í‰ê·  ì²­ì†Œë¹„: {row['Cleaning_Fee_mean']}ì› / í‰ê·  ì—ì–´ë¹„ì•¤ë¹„ ìˆ˜ìˆ˜ë£Œ: {row['Airbnb_Service_Fee_mean']}ì›\n"
        f"í‰ê·  1ë°• ì´ìš”ê¸ˆ: {row['total_price_mean']}ì›\n"
    )



# ì„ë² ë”© í…ìŠ¤íŠ¸ì™€ ë²¡í„° ìƒì„±
final_df_price['embedding_text'] = final_df_price.apply(build_embedding_text, axis=1)
embeddings = embedding_model.encode(final_df_price['embedding_text'].tolist(), show_progress_bar=True, batch_size=64)

# numpy arrayë¡œ ë³€í™˜
dense_vectors = np.array(embeddings)

# ì €ì¥ (Listing ID í¬í•¨ DF ìœ ì§€)
with open("/content/drive/MyDrive/dataset/airbnb_data_price(ì „ì²˜ë¦¬ì¶”ê°€).pkl", "wb") as f:
    pickle.dump({
        "df": final_df_price[['Airbnb_ListingID', 'embedding_text'] +
                      [c for c in final_df_price.columns if c not in ['Airbnb_ListingID', 'embedding_text']]],
        "vectors": dense_vectors
    }, f)

print("âœ… Pickle ì €ì¥ ì™„ë£Œ: /content/drive/MyDrive/dataset/airbnb_data_price(ì „ì²˜ë¦¬ì¶”ê°€).pkl")

