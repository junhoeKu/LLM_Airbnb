import folium
from folium.plugins import MarkerCluster

# ê¸°ëŠ¥ ëª¨ë“ˆ import
from agent.check_rag import agent_check_rag_need
from agent.expand_query import agent_expand_and_extract_columns
from agent.extract_user_req import extract_user_requirements
from search.smart_search import smart_rag_search
from search.filter_results import filter_results_by_requirements
from response.generate_response import generate_context_aware_response
from utils.map_utils import create_map_from_results
from utils.response_utils import generate_free_response

# configì—ì„œ ì „ì—­ ìì› import
from config import chat_history, embedding_model, index, df, price_index, price_df, client

# pip install --upgrade streamlit openai sentence-transformers faiss-gpu numpy
# pip install transformers==4.45.2
# streamlit run app.py

def chat_interface(query, history):
    """ê°œì„ ëœ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ í•¨ìˆ˜
    ë©€í‹°í„´ ëŒ€í™” ì§€ì› ë° ì¡°ê±´ ì¶©ì¡± ê²€ì‚¬ ê°•í™”

    Args:
        query: ì‚¬ìš©ì ì¿¼ë¦¬
        history: ëŒ€í™” ê¸°ë¡

    Returns:
        ì—…ë°ì´íŠ¸ëœ ëŒ€í™” ê¸°ë¡, ì±„íŒ… ê¸°ë¡, ì§€ë„ HTML
    """
    history = history or []
    try:
        # RAG í•„ìš” ì—¬ë¶€ í™•ì¸
        rag_needed = agent_check_rag_need(query)

        if not rag_needed:
            # ì¼ë°˜ ëŒ€í™” ì‘ë‹µ
            bot_response = generate_free_response(query)
            chat_history.append({"role": "user", "content": query})  # â† config.chat_history ì‚¬ìš©
            map_html = ""
        else:
            # ëŒ€í™” ê¸°ë¡ ì¶”ê°€ í›„ ì¿¼ë¦¬ í™•ì¥ ë° ì»¬ëŸ¼ ì¶”ì¶œ
            chat_history.append({"role": "user", "content": query})
            expanded_query, required_columns, db_type = agent_expand_and_extract_columns(query, chat_history)

            # ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ
            user_requirements = extract_user_requirements(query, chat_history)

            # ê°œì„ ëœ ê²€ìƒ‰
            search_results = smart_rag_search(
                expanded_query,
                required_columns,
                db_type,
                user_requirements
            )

            # ì‘ë‹µ ìƒì„±
            bot_response, recommended_ids = generate_context_aware_response(
                expanded_query,
                search_results,
                required_columns,
                db_type,
                user_requirements
            )

            # ì§€ë„ ìƒì„±
            map_html = create_map_from_results(search_results, highlight_ids=recommended_ids)

        # ëŒ€í™” ê¸°ë¡ ì—…ë°ì´íŠ¸
        chat_history.append({"role": "assistant", "content": bot_response})
        history.append((query, bot_response))

        return history, history, map_html

    except Exception as e:
        error_msg = f"â— ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        history.append((query, error_msg))
        return history, history, f"<b>ğŸ›‘ ì˜¤ë¥˜ ë°œìƒ:</b><br>{str(e)}"